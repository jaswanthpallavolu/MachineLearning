{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import dependencies\n",
    "import numpy\n",
    "import sys\n",
    "import urllib\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "file = open('frankstein.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization \n",
    "# standardization\n",
    "def tokenize_words(input) :\n",
    "    input = input.lower()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(input)\n",
    "    filtered = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
    "    return \" \".join(filtered)\n",
    "\n",
    "processed_inputs = tokenize_words(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chars to numbers\n",
    "chars = sorted(list(set(processed_inputs)))\n",
    "char_to_num = dict((c,i) for i,c in enumerate(chars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters 83157\n",
      "Total vocab: 41\n"
     ]
    }
   ],
   "source": [
    "# check if words to chars or chars to num (?:) has worked?\n",
    "input_len = len(processed_inputs)\n",
    "vocab_len = len(chars)\n",
    "print('Total number of characters',input_len)\n",
    "print('Total vocab:',vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq length\n",
    "seq_length = 100\n",
    "x_data = []\n",
    "y_data = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns :  83057\n"
     ]
    }
   ],
   "source": [
    "#loop through the sequence\n",
    "for i in range(0, input_len - seq_length, 1):\n",
    "    in_seq = processed_inputs[i:i + seq_length]\n",
    "    out_seq = processed_inputs[i + seq_length]\n",
    "    x_data.append([char_to_num[char] for char in in_seq])\n",
    "    y_data.append([char_to_num[out_seq]])\n",
    "\n",
    "n_patterns = len(x_data)\n",
    "print('Total Patterns : ',n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert input seq to np array and so on\n",
    "X = numpy.reshape(x_data,(n_patterns, seq_length, 1))\n",
    "X = X/float(vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding\n",
    "y = np_utils.to_categorical(y_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1],X.shape[2]),return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving weights\n",
    "filepath = 'model_weights_saved.hdf5'\n",
    "checkpoint =  ModelCheckpoint(filepath,monitor='loss',verbose = 1,save_best_only=True, mode='min')\n",
    "desired_callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "83057/83057 [==============================] - 201s 2ms/step - loss: 2.9624\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.96239, saving model to model_weights_saved.hdf5\n",
      "Epoch 2/4\n",
      "83057/83057 [==============================] - 198s 2ms/step - loss: 2.9228\n",
      "\n",
      "Epoch 00002: loss improved from 2.96239 to 2.92280, saving model to model_weights_saved.hdf5\n",
      "Epoch 3/4\n",
      "83057/83057 [==============================] - 197s 2ms/step - loss: 2.8809\n",
      "\n",
      "Epoch 00003: loss improved from 2.92280 to 2.88093, saving model to model_weights_saved.hdf5\n",
      "Epoch 4/4\n",
      "83057/83057 [==============================] - 198s 2ms/step - loss: 2.7077\n",
      "\n",
      "Epoch 00004: loss improved from 2.88093 to 2.70765, saving model to model_weights_saved.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5be5289e48>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model let it train\n",
    "model.fit(X,y,epochs=4, batch_size=256, callbacks=desired_callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recompile model with the saved weights\n",
    "filename = 'model_weights_saved.hdf5'\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output  of the model back into characters\n",
    "num_to_char = dict((i,c) for i,c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed :\n",
      "\" es nature show works hiding places ascend heavens discovered blood circulates nature air breathe acq \"\n"
     ]
    }
   ],
   "source": [
    "#random seed to help generate\n",
    "start = numpy.random.randint(0,len(x_data)-1)\n",
    "pattern = x_data[start]\n",
    "print('Random Seed :')\n",
    "print(\"\\\"\",''.join([num_to_char[value] for value in pattern]) , \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere sere ser"
     ]
    }
   ],
   "source": [
    "# generate the text\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1,len(pattern), 1))\n",
    "    x = x/float(vocab_len)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = num_to_char[index]\n",
    "    seq_in = [num_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
