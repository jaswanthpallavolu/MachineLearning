{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import dependencies\n",
    "import numpy\n",
    "import sys\n",
    "import urllib\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "file = open('frankstein.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization \n",
    "# standardization\n",
    "def tokenize_words(input) :\n",
    "    input = input.lower()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(input)\n",
    "    filtered = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
    "    return \" \".join(filtered)\n",
    "\n",
    "processed_inputs = tokenize_words(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chars to numbers\n",
    "chars = sorted(list(set(processed_inputs)))\n",
    "char_to_num = dict((c,i) for i,c in enumerate(chars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters 83157\n",
      "Total vocab: 41\n"
     ]
    }
   ],
   "source": [
    "# check if words to chars or chars to num (?:) has worked?\n",
    "input_len = len(processed_inputs)\n",
    "vocab_len = len(chars)\n",
    "print('Total number of characters',input_len)\n",
    "print('Total vocab:',vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq length\n",
    "seq_length = 100\n",
    "x_data = []\n",
    "y_data = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns :  83057\n"
     ]
    }
   ],
   "source": [
    "#loop through the sequence\n",
    "for i in range(0, input_len - seq_length, 1):\n",
    "    in_seq = processed_inputs[i:i + seq_length]\n",
    "    out_seq = processed_inputs[i + seq_length]\n",
    "    x_data.append([char_to_num[char] for char in in_seq])\n",
    "    y_data.append([char_to_num[out_seq]])\n",
    "\n",
    "n_patterns = len(x_data)\n",
    "print('Total Patterns : ',n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert input seq to np array and so on\n",
    "X = numpy.reshape(x_data,(n_patterns, seq_length, 1))\n",
    "X = X/float(vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding\n",
    "y = np_utils.to_categorical(y_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1],X.shape[2]),return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving weights\n",
    "filepath = 'model_weights_saved.hdf5'\n",
    "checkpoint =  ModelCheckpoint(filepath,monitor='loss',verbose = 1,save_best_only=True, mode='min')\n",
    "desired_callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "83057/83057 [==============================] - 201s 2ms/step - loss: 2.6434\n",
      "\n",
      "Epoch 00001: loss improved from 2.70765 to 2.64343, saving model to model_weights_saved.hdf5\n",
      "Epoch 2/20\n",
      "83057/83057 [==============================] - 197s 2ms/step - loss: 2.5826\n",
      "\n",
      "Epoch 00002: loss improved from 2.64343 to 2.58263, saving model to model_weights_saved.hdf5\n",
      "Epoch 3/20\n",
      "83057/83057 [==============================] - 198s 2ms/step - loss: 2.5181\n",
      "\n",
      "Epoch 00003: loss improved from 2.58263 to 2.51809, saving model to model_weights_saved.hdf5\n",
      "Epoch 4/20\n",
      "83057/83057 [==============================] - 199s 2ms/step - loss: 2.4641\n",
      "\n",
      "Epoch 00004: loss improved from 2.51809 to 2.46414, saving model to model_weights_saved.hdf5\n",
      "Epoch 5/20\n",
      "83057/83057 [==============================] - 198s 2ms/step - loss: 2.4134\n",
      "\n",
      "Epoch 00005: loss improved from 2.46414 to 2.41337, saving model to model_weights_saved.hdf5\n",
      "Epoch 6/20\n",
      "83057/83057 [==============================] - 197s 2ms/step - loss: 2.3679\n",
      "\n",
      "Epoch 00006: loss improved from 2.41337 to 2.36786, saving model to model_weights_saved.hdf5\n",
      "Epoch 7/20\n",
      "83057/83057 [==============================] - 197s 2ms/step - loss: 2.3228\n",
      "\n",
      "Epoch 00007: loss improved from 2.36786 to 2.32280, saving model to model_weights_saved.hdf5\n",
      "Epoch 8/20\n",
      "83057/83057 [==============================] - 197s 2ms/step - loss: 2.2834\n",
      "\n",
      "Epoch 00008: loss improved from 2.32280 to 2.28342, saving model to model_weights_saved.hdf5\n",
      "Epoch 9/20\n",
      "83057/83057 [==============================] - 197s 2ms/step - loss: 2.2450\n",
      "\n",
      "Epoch 00009: loss improved from 2.28342 to 2.24496, saving model to model_weights_saved.hdf5\n",
      "Epoch 10/20\n",
      "83057/83057 [==============================] - 196s 2ms/step - loss: 2.2172\n",
      "\n",
      "Epoch 00010: loss improved from 2.24496 to 2.21725, saving model to model_weights_saved.hdf5\n",
      "Epoch 11/20\n",
      "83057/83057 [==============================] - 197s 2ms/step - loss: 2.1866\n",
      "\n",
      "Epoch 00011: loss improved from 2.21725 to 2.18662, saving model to model_weights_saved.hdf5\n",
      "Epoch 12/20\n",
      "83057/83057 [==============================] - 197s 2ms/step - loss: 2.1635\n",
      "\n",
      "Epoch 00012: loss improved from 2.18662 to 2.16348, saving model to model_weights_saved.hdf5\n",
      "Epoch 13/20\n",
      "83057/83057 [==============================] - 198s 2ms/step - loss: 2.1340\n",
      "\n",
      "Epoch 00013: loss improved from 2.16348 to 2.13396, saving model to model_weights_saved.hdf5\n",
      "Epoch 14/20\n",
      "83057/83057 [==============================] - 197s 2ms/step - loss: 2.1076\n",
      "\n",
      "Epoch 00014: loss improved from 2.13396 to 2.10760, saving model to model_weights_saved.hdf5\n",
      "Epoch 15/20\n",
      "83057/83057 [==============================] - 197s 2ms/step - loss: 2.0833\n",
      "\n",
      "Epoch 00015: loss improved from 2.10760 to 2.08334, saving model to model_weights_saved.hdf5\n",
      "Epoch 16/20\n",
      "83057/83057 [==============================] - 197s 2ms/step - loss: 2.0637\n",
      "\n",
      "Epoch 00016: loss improved from 2.08334 to 2.06372, saving model to model_weights_saved.hdf5\n",
      "Epoch 17/20\n",
      "83057/83057 [==============================] - 197s 2ms/step - loss: 2.0420\n",
      "\n",
      "Epoch 00017: loss improved from 2.06372 to 2.04201, saving model to model_weights_saved.hdf5\n",
      "Epoch 18/20\n",
      "83057/83057 [==============================] - 197s 2ms/step - loss: 2.0252\n",
      "\n",
      "Epoch 00018: loss improved from 2.04201 to 2.02521, saving model to model_weights_saved.hdf5\n",
      "Epoch 19/20\n",
      "83057/83057 [==============================] - 197s 2ms/step - loss: 2.0084\n",
      "\n",
      "Epoch 00019: loss improved from 2.02521 to 2.00836, saving model to model_weights_saved.hdf5\n",
      "Epoch 20/20\n",
      "83057/83057 [==============================] - 197s 2ms/step - loss: 1.9875\n",
      "\n",
      "Epoch 00020: loss improved from 2.00836 to 1.98752, saving model to model_weights_saved.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5bdf6729e8>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model let it train\n",
    "model.fit(X,y,epochs=20, batch_size=256, callbacks=desired_callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recompile model with the saved weights\n",
    "filename = 'model_weights_saved.hdf5'\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output  of the model back into characters\n",
    "num_to_char = dict((i,c) for i,c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed :\n",
      "\" ersuade relatives commence use would pursuit could arrest creature capable scaling overhanging sides \"\n"
     ]
    }
   ],
   "source": [
    "#random seed to help generate\n",
    "start = numpy.random.randint(0,len(x_data)-1)\n",
    "pattern = x_data[start]\n",
    "print('Random Seed :')\n",
    "print(\"\\\"\",''.join([num_to_char[value] for value in pattern]) , \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared sear consinued seared s"
     ]
    }
   ],
   "source": [
    "# generate the text\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1,len(pattern), 1))\n",
    "    x = x/float(vocab_len)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = num_to_char[index]\n",
    "    seq_in = [num_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
